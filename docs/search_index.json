[["Introduction.html", "Rで計量経済学 Chapter 1 イントロダクション 1.1 環境構築 1.2 基本的な計算 1.3 ベクトル 1.4 データフレーム 1.5 データの型", " Rで計量経済学 Tomoya Ozawa Last Update: 03/26/2021 Chapter 1 イントロダクション 1.1 環境構築 こちらの資料をもとにR studioのセットアップをしてみてください。R studio cloudも使い勝手がいいです。 1.2 基本的な計算 まずは、基本的な計算をRでやってみましょう。電卓みたいに使ってみます。足し算と引き算はイメージ通りだと思います。 1+1 ## [1] 2 1-1 ## [1] 0 掛け算は×ではなくて、*。割り算は÷ではなくて、/です。ちなみに、商は%/%、余りは%% 1*2 ## [1] 2 4/2 ## [1] 2 5%/%2 ## [1] 2 5%%2 ## [1] 1 累乗は^、ルートはsqrt()です。 2^3 ## [1] 8 sqrt(4) ## [1] 2 計算結果をオブジェクトに代入することもできます。（計算結果に名前をつけるイメージ）下の場合だと、2+2の結果をaというオブジェクトに代入しているイメージです。Rで代入する時には、&lt;-がよく使われます。=でも動きます。 a &lt;- 2+2 a ## [1] 4 1.3 ベクトル a &lt;- c(1, 2, 3, 4) a ## [1] 1 2 3 4 sum()を使うと、そのベクトルの合計値が取得できます。 sum(a) ## [1] 10 mean()は平均値、median()は中央値です。 mean(a) ## [1] 2.5 最大値、最小値もそれぞれmax()``min()で取得出来ます。print()を使うと、その名の通り結果を出力出来ます。 print(max(a)) ## [1] 4 print(min(a)) ## [1] 1 ベクトルの要素として、文字もOKです。文字の場合は数字やオブジェクトと区別するために\"\"で囲います。 vec &lt;- c(&quot;Mario&quot;, &quot;Luigi&quot;, &quot;Princess Peach&quot;) vec ## [1] &quot;Mario&quot; &quot;Luigi&quot; &quot;Princess Peach&quot; []でベクトルの要素を抽出することも出来ます。 vec[2] ## [1] &quot;Luigi&quot; 複数の要素も抽出可能です。 vec[c(1, 3)] # 1つ目と3つ目 ## [1] &quot;Mario&quot; &quot;Princess Peach&quot; vec[2:3] # 2~3つ目 ## [1] &quot;Luigi&quot; &quot;Princess Peach&quot; ベクトルの要素の数を取得する際には、length()を使います length(vec) ## [1] 3 行列みたいに計算も出来ます。ベクトルの要素ごとに計算されます。行列積は%*%です。 a &lt;- c(1, 2, 3, 4) b &lt;- c(5, 6, 7, 8) print(a+b) ## [1] 6 8 10 12 print(a-b) ## [1] -4 -4 -4 -4 print(a*b) ## [1] 5 12 21 32 print(a%*%b) ## [,1] ## [1,] 70 1.4 データフレーム データフレームは列方向にベクトルを集めたものです。エクセル上でよくみるデータのことです。以下の例だと、id(学生番号)、height(身長)、sex(性別)ベクトルを列方向に集めています。 id &lt;- c(1, 2, 3) height &lt;- c(180, 170, 160) sex &lt;- c(&quot;男性&quot;, &quot;男性&quot;, &quot;女性&quot;) idベクトルにはIDという列名を、heightベクトルにはHEIGHTという列名をつけてデータフレームにしています。データフレームを作る時にはdata.frame()を使います。 df &lt;- data.frame(ID = id, HEIGHT = height, SEX = sex) head(df) ## ID HEIGHT SEX ## 1 1 180 男性 ## 2 2 170 男性 ## 3 3 160 女性 データフレームから任意の列を抽出する際には、以下のように$を使います。 df$ID # ID列のベクトルを取得 ## [1] 1 2 3 このデータフレームを分析していくことが実証分析の基本的な作業になります。実際に分析手法を学ぶ際に、このデータフレームの扱い方も学んでいきましょう。 1.5 データの型 1.5.1 数値 データには型というものが存在します。class()を使うと型がわかります。numericは数値です。計算する時にはデータの型は数値である必要があります。 a &lt;- 5 class(a) ## [1] &quot;numeric&quot; 1.5.2 文字 数字の5でも、時には文字として扱いたい時もあるはずです。この場合は、\"\"で囲ってあげます。この型をclass()でみてみると、characterと表示され、文字列として認識されていることがわかります。 a &lt;- &quot;5&quot; class(a) ## [1] &quot;character&quot; 文字列を数値として扱いたい時はas.numeric()、その逆はas.numeric()で出来ます。 a &lt;- &quot;5&quot; a &lt;- as.numeric(a) print(a) ## [1] 5 print(class(a)) ## [1] &quot;numeric&quot; 1.5.3 論理演算子 最後に、論理演算子を紹介します。これは、TRUEとFALSEの2値をとる型で、class()でみてみるとlogicalと表示されます。YES, NOで答えられるデータを扱う際に使うことが多いです。 answer &lt;- c(TRUE, FALSE, TRUE) class(answer) ## [1] &quot;logical&quot; 先ほど、計算するにはデータの型が数値である必要があるという話がありましたが、実は論理演算子も計算することが出来ます。例えば、合計を算出する関数であるsum()を使うと、以下のようにTRUEの数が集計されます。 sum(answer) ## [1] 2 "],["OLS.html", "Chapter 2 回帰分析 2.1 検証する仮説 2.2 データの読み込み 2.3 データの把握 2.4 単回帰分析 2.5 重回帰分析 2.6 捕捉：多重共線性", " Chapter 2 回帰分析 2.1 検証する仮説 「教育年数が増えると,賃金は増加するのでは?」という仮説を検証していきます。 2.2 データの読み込み データを読み込む際はread.csv()関数を使います。()の中で読み込みたいデータがあるファイル名を指定してます。このコードの場合、カレントディレクトリの中のdataというフォルダ内にあるデータfemale_labor.csvを読み込むという操作をしています。Rのディレクトリ関連の話はここに詳しくまとまっています。そもそもディレクトリってなんやねんと感じている方はこちらを参照してください。 head()関数でデータの先頭6行を出力することが出来ます。反対に、tail()とすると後ろから6行を出力出来ます df &lt;- read.csv(&quot;data/female_labor.csv&quot;) head(df) ## working_hours age education hourly_wage mother_edu ## 1 4950 35 12 0.1616 10 ## 2 4210 46 12 2.3753 3 ## 3 3686 32 14 0.5426 12 ## 4 3640 58 12 1.0989 7 ## 5 3533 38 15 5.0948 12 ## 6 3225 54 16 3.0416 12 ## father_edu number_kids_under6 number_kids_6to18 ## 1 10 0 2 ## 2 3 0 0 ## 3 12 0 0 ## 4 3 0 0 ## 5 7 2 2 ## 6 12 0 0 ○変数の説明 変数名 説明 working_hous 労働時間 age 年齢 education 教育年数 hourly_wage 時給（ドル） mother_edu 母親の教育年数 father_edu 父親の教育年数 number_kids_under6 6才未満の子供の数 number_kids_6to18 6〜18才の子供の数 2.3 データの把握 2.3.1 ヒストグラム 分析に入る前にデータを可視化していきます。1つの変数の分布を把握する時にはhist()を使います。()内でデータの指定をします。今回はdfという名前のデータのeducationという変数のヒストグラムを出力しています。 hist(df$education) hist(df$hourly_wage) 2.3.2 散布図 2つの変数の関係を可視化する際には、plot()という関数を使います。()内でデータを2つ指定します。 plot(df$education, df$hourly_wage) 2.3.3 基本統計量 データの傾向を統計学で学んだ指標で理解してみましょう。summary()関数を使うと、()内で指定したデータの各変数について基本統計量を出力してくれます。NA'sは欠損値の個数を示しています。欠損値は数値が入ってない、不明な値のことです。 summary(df) ## working_hours age education ## Min. : 0.0 Min. :30.00 Min. : 5.00 ## 1st Qu.: 0.0 1st Qu.:36.00 1st Qu.:12.00 ## Median : 288.0 Median :43.00 Median :12.00 ## Mean : 740.6 Mean :42.54 Mean :12.29 ## 3rd Qu.:1516.0 3rd Qu.:49.00 3rd Qu.:13.00 ## Max. :4950.0 Max. :60.00 Max. :17.00 ## ## hourly_wage mother_edu father_edu ## Min. : 0.000 Min. : 3.000 Min. : 3.000 ## 1st Qu.: 0.000 1st Qu.: 7.000 1st Qu.: 7.000 ## Median : 1.625 Median :10.000 Median : 7.000 ## Mean : 2.375 Mean : 9.414 Mean : 8.988 ## 3rd Qu.: 3.788 3rd Qu.:12.000 3rd Qu.:12.000 ## Max. :25.000 Max. :17.000 Max. :17.000 ## NA&#39;s :13 NA&#39;s :15 ## number_kids_under6 number_kids_6to18 ## Min. :0.0000 Min. :0.000 ## 1st Qu.:0.0000 1st Qu.:0.000 ## Median :0.0000 Median :1.000 ## Mean :0.2377 Mean :1.353 ## 3rd Qu.:0.0000 3rd Qu.:2.000 ## Max. :3.0000 Max. :8.000 ## 2.4 単回帰分析 2.4.1 計量経済学モデル \\[ hourly\\_wage_{i} = \\alpha + \\beta\\times education_{i} + u_{i} \\] 2.4.2 推定 回帰分析をする際には、lm(被説明変数 ~ 説明変数, data = データの名前)関数を使います。()内で①回帰式と②使用するデータの2つを指定します。このコードだと、結果はout_simple_regressというオブジェクトに保存されます。 out_simple_regress &lt;- lm(hourly_wage ~ education, data = df) 2.4.3 解釈 回帰分析の結果はsummary()関数で確認することができます。()内に分析結果のオブジェクトを入れます。 summary(out_simple_regress) ## ## Call: ## lm(formula = hourly_wage ~ education, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.5079 -2.2447 -0.4342 1.3737 22.7553 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.18694 0.61456 -5.186 2.77e-07 *** ## education 0.45264 0.04918 9.204 &lt; 2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.075 on 751 degrees of freedom ## Multiple R-squared: 0.1014, Adjusted R-squared: 0.1002 ## F-statistic: 84.71 on 1 and 751 DF, p-value: &lt; 2.2e-16 先ほどの散布図に推定した回帰式をくっつけてみましょう。図に線を足す時にはabline()関数を使います。今回はcol=\"blue\"で直線の色を青色に指定しました。推定結果のeducationのEstimateが推定されたパラメータ\\(\\alpha\\)の値を示しています。0.45264と正の値なので、右肩上がりの直線になりそうですね。 plot(df$education, df$hourly_wage) abline(out_simple_regress, col = &quot;blue&quot;) 2.5 重回帰分析 2.5.1 計量経済学モデル 次に、説明変数が2つ以上ある回帰モデル、重回帰分析を扱います。想定する回帰式は以下の通りです。 \\[ hourly\\_wage_{i} = \\alpha + \\beta_{1}\\times education_{i}+ \\beta_{2}\\times age_{i} + \\beta_{3}\\times working\\_dummy_{i} + \\beta_{4}\\times mother\\_edu_{i} + \\beta_{5}\\times father\\_edu_{i} + \\beta_{6}\\times number\\_kids_{i}+ u_{i} \\] 2.5.2 データの加工: 新規変数作成 18才以下の子供の数を示すnumber_kidsという変数を作成してみましょう。number_kids_under6とnumber_kids_6to18の和がこの値になります。&lt;-は代入を示しています。つまり、number_kidsという変数はnumber_kids_under6+number_kids_6to18で得られる結果を代入した値となります。head()関数で出力したデータをみて、正しく作られているか確認しましょう。 df$number_kids &lt;- df$number_kids_under6 + df$number_kids_6to18 head(df) ## working_hours age education hourly_wage mother_edu ## 1 4950 35 12 0.1616 10 ## 2 4210 46 12 2.3753 3 ## 3 3686 32 14 0.5426 12 ## 4 3640 58 12 1.0989 7 ## 5 3533 38 15 5.0948 12 ## 6 3225 54 16 3.0416 12 ## father_edu number_kids_under6 number_kids_6to18 ## 1 10 0 2 ## 2 3 0 0 ## 3 12 0 0 ## 4 3 0 0 ## 5 7 2 2 ## 6 12 0 0 ## number_kids ## 1 2 ## 2 0 ## 3 0 ## 4 0 ## 5 4 ## 6 0 2.5.3 データの加工: 欠損値の処理 最初の方でデータの基本統計量を確認した際にmother_eduとfather_eduに欠損値NAがありました。今回はこのNAを埋めてみましょう。今回は欠損している箇所は0、つまり教育を受けていない人と解釈します。欠損値を処理する際には、欠損していることに意味があるのかどうか？をしっかり考えてください。 # dfの欠損値を全て0にする df[is.na(df)] &lt;- 0 # あるいはdfのmother_eduという列の欠損値を0にする df$mother_edu[is.na(df$mother_edu)] &lt;- 0 # 欠損値を含む行を削除する場合は na.omit(df) 2.5.4 データの加工: ダミー変数 ダミー変数とは、ある条件を満たしたら1をそれ以外であれば0の2値だけをとる変数のことです。今回はworking_dummyという働いているかいないかを示すダミー変数を作ってみます。ifelse(条件, 条件に合う場合, 合わない場合)関数を使うと簡単に作ることが出来ます。今回はworking_hours&gt;0を条件として、これを満たせば1を満たさなければ0を取るとしています。 df$working_dummy &lt;- ifelse(df$working_hours&gt;0, 1,0) 2.5.5 推定 重回帰分析も同様にlm()関数を使います。説明変数を+で繋げていきます。 out_multi_regress &lt;- lm(hourly_wage ~ education + age + working_dummy + mother_edu + father_edu + number_kids, data = df ) 2.5.6 解釈 これも単回帰と同様にsummary関数です。 summary(out_multi_regress) ## ## Call: ## lm(formula = hourly_wage ~ education + age + working_dummy + ## mother_edu + father_edu + number_kids, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.9952 -1.1097 -0.1540 0.4855 21.3594 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.573959 0.851078 -4.199 3.00e-05 *** ## education 0.333712 0.044951 7.424 3.11e-13 *** ## age 0.006085 0.013058 0.466 0.6414 ## working_dummy 3.921522 0.182158 21.528 &lt; 2e-16 *** ## mother_edu -0.056667 0.033289 -1.702 0.0891 . ## father_edu -0.003238 0.031124 -0.104 0.9172 ## number_kids -0.054553 0.070483 -0.774 0.4392 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.406 on 746 degrees of freedom ## Multiple R-squared: 0.4536, Adjusted R-squared: 0.4492 ## F-statistic: 103.2 on 6 and 746 DF, p-value: &lt; 2.2e-16 lm(formula = hourly_wage ~ education, data = df): 回帰式を再掲しています。 Residuals: 誤差項 \\(u_i\\)の分布 Coefficients: Estimate: パラメータ$, _1,_2, ,_6 $の値 Std. Error: 標準誤差 t value: t値 Pr(&gt;|t|): p値, 0~0.001の間なら***, 0.001~0.01の間なら**, 0.01~0.05の間なら*が付きます。 Multiple R-squared: 決定係数の値です。重回帰分析の場合はAdjusted R-squared（自由度調整済み決定係数）をみます。 F-statistic: F値 このようにパラメータの値だけを取り出すことも出来ます。 out_multi_regress$coefficients ## (Intercept) education age working_dummy ## -3.573959289 0.333711958 0.006084630 3.921521509 ## mother_edu father_edu number_kids ## -0.056666781 -0.003237767 -0.054553491 2.6 捕捉：多重共線性 2.6.1 相関係数 説明変数間で強い相関がみられると、パラメータの推定値にバイアスがかかってしまいます。そのため、重回帰分析の前に説明変数間での相関係数をチェックすることが望ましいです。cor()関数で相関係数を出力することが出来ます。 cor(df) ## working_hours age education ## working_hours 1.00000000 -0.03311418 0.10596042 ## age -0.03311418 1.00000000 -0.12022299 ## education 0.10596042 -0.12022299 1.00000000 ## hourly_wage 0.42294447 -0.03455914 0.31837807 ## mother_edu 0.05786375 -0.23464156 0.43533650 ## father_edu 0.01367090 -0.16059085 0.44245823 ## number_kids_under6 -0.22206330 -0.43394869 0.10869022 ## number_kids_6to18 -0.09063207 -0.38541134 -0.05889891 ## number_kids -0.16157352 -0.50398872 -0.01423498 ## working_dummy 0.74114539 -0.08049811 0.18735285 ## hourly_wage mother_edu father_edu ## working_hours 0.42294447 0.05786375 0.01367090 ## age -0.03455914 -0.23464156 -0.16059085 ## education 0.31837807 0.43533650 0.44245823 ## hourly_wage 1.00000000 0.09030522 0.09847684 ## mother_edu 0.09030522 1.00000000 0.57307174 ## father_edu 0.09847684 0.57307174 1.00000000 ## number_kids_under6 -0.12289534 0.10782888 0.09607595 ## number_kids_6to18 -0.04734860 0.03238278 -0.02683041 ## number_kids -0.08687983 0.06794962 0.01022068 ## working_dummy 0.63870803 0.09048973 0.05771841 ## number_kids_under6 number_kids_6to18 ## working_hours -0.22206330 -0.090632070 ## age -0.43394869 -0.385411341 ## education 0.10869022 -0.058898912 ## hourly_wage -0.12289534 -0.047348598 ## mother_edu 0.10782888 0.032382782 ## father_edu 0.09607595 -0.026830408 ## number_kids_under6 1.00000000 0.084159872 ## number_kids_6to18 0.08415987 1.000000000 ## number_kids 0.43481542 0.933918807 ## working_dummy -0.21374930 -0.002424231 ## number_kids working_dummy ## working_hours -0.16157352 0.741145387 ## age -0.50398872 -0.080498109 ## education -0.01423498 0.187352846 ## hourly_wage -0.08687983 0.638708027 ## mother_edu 0.06794962 0.090489728 ## father_edu 0.01022068 0.057718407 ## number_kids_under6 0.43481542 -0.213749303 ## number_kids_6to18 0.93391881 -0.002424231 ## number_kids 1.00000000 -0.078875105 ## working_dummy -0.07887511 1.000000000 cor()関数で相関係数は問題なく出力できますが、如何せん見にくいです。psychライブラリのcor.plot()関数を使うと、見やすく相関係数を可視化してくれます。psychライブラリを初めて使う方はinstall.packages(\"psych\")を実行してください。 library(psych) cor.plot(cor(df)) 2.6.2 VIF統計量 VIF統計量は多重共線性の疑いを定量化できる指標です。10以上の値がでたら怪しんだ方が良いみたいです。理想は2以下らしいです。 library(car) ## Loading required package: carData ## ## Attaching package: &#39;car&#39; ## The following object is masked from &#39;package:psych&#39;: ## ## logit vif(out_multi_regress) ## education age working_dummy mother_edu ## 1.364894 1.443657 1.058935 1.632561 ## father_edu number_kids ## 1.605999 1.376647 "],["IV.html", "Chapter 3 操作変数法 3.1 検証する仮説 3.2 データの読み込み 3.3 データの把握 3.4 推定 3.5 推定結果の整理", " Chapter 3 操作変数法 操作変数自体の説明はこちらからどうぞ。 3.1 検証する仮説 「追加的に子供を出産することで、出産後の労働時間が減少するのではないか？」という仮説を検証していきます。出産が労働時間に与える影響がテーマです。Angrist and Evans(1998)の再現です。 3.2 データの読み込み 今回使用するデータはU.S. census (1980年)の既婚女性に関するもので、22~ 35歳の2人以上の子供を持つ既婚女性,計254,654人が対象です。 df &lt;- read.csv(&#39;data/labsup_edited.csv&#39;) head(df) ## morekids boy1st boy2nd samesex agem1 black hispan ## 1 0 1 0 0 27 0 0 ## 2 0 0 1 0 30 0 0 ## 3 0 1 0 0 27 0 0 ## 4 0 1 0 0 35 1 0 ## 5 0 0 0 1 30 0 0 ## 6 0 1 0 0 26 0 0 ## othrace weeksm1 ## 1 0 0 ## 2 0 30 ## 3 0 0 ## 4 0 0 ## 5 0 22 ## 6 0 40 ○変数の説明 変数名 説明 morekids 子供が3人以上いる母親なら1をとるダミー変数 boy1st 最初の子供が男なら1をとるダミー変数 boy2nd 2番目の子供が男なら1をとるダミー変数 samesex 最初と2番目の子供の性別が同じなら1をとるダミー変数 agem1 母親が初めて出産した時の年齢 black 母親が黒人なら1をとるダミー変数 hispan 母親がヒスパニック系なら1をとるダミー変数 othrace 母親が黒人・ヒスパニック系以外なら1をとるダミー変数 weeksm1 1979年の母親の週の平均労働時間 3.3 データの把握 データの特徴を把握していきます。欠損値は特になさそうです。weeksm1を見ると、働いてない女性も結構いますね。 summary(df) ## morekids boy1st boy2nd ## Min. :0.0000 Min. :0.0000 Min. :0.0000 ## 1st Qu.:0.0000 1st Qu.:0.0000 1st Qu.:0.0000 ## Median :0.0000 Median :1.0000 Median :1.0000 ## Mean :0.3806 Mean :0.5144 Mean :0.5126 ## 3rd Qu.:1.0000 3rd Qu.:1.0000 3rd Qu.:1.0000 ## Max. :1.0000 Max. :1.0000 Max. :1.0000 ## samesex agem1 black ## Min. :0.0000 Min. :21.00 Min. :0.00000 ## 1st Qu.:0.0000 1st Qu.:28.00 1st Qu.:0.00000 ## Median :1.0000 Median :31.00 Median :0.00000 ## Mean :0.5056 Mean :30.39 Mean :0.05166 ## 3rd Qu.:1.0000 3rd Qu.:33.00 3rd Qu.:0.00000 ## Max. :1.0000 Max. :35.00 Max. :1.00000 ## hispan othrace weeksm1 ## Min. :0.00000 Min. :0.00000 Min. : 0.00 ## 1st Qu.:0.00000 1st Qu.:0.00000 1st Qu.: 0.00 ## Median :0.00000 Median :0.00000 Median : 5.00 ## Mean :0.07421 Mean :0.05634 Mean :19.02 ## 3rd Qu.:0.00000 3rd Qu.:0.00000 3rd Qu.:44.00 ## Max. :1.00000 Max. :1.00000 Max. :52.00 3.4 推定 今回興味のある変数はmorekidsです。このパラメータが負であれば、仮説は検証されます。このままOLS推定してもいいですが、その場合には内生性が生じている状況での推定になります。具体的には、働きたくない人（労働時間を短い人）ほど、子供を多く出産するという逆の因果性が考えられます。この逆の因果性は需要関数を推定する際にも生じうる問題です。そこで、今回は操作変数法という手法で、この逆の因果性に対処してみます。 3.4.1 計量経済学モデル 1段階目 \\[ morekids_{i} = \\alpha + \\beta_{1}\\times samesex_{i}+ \\beta_{2}\\times agem1_{i}+ \\beta_{3}\\times black_{i}+ \\beta_{4}\\times hispan_{i} + \\beta_{5}\\times othrace_{i} + u_{i} \\] 2段階目 \\[ weeksm1_{i} = \\alpha + \\beta_{1}\\times \\widehat{morekids_{i}}+ \\beta_{2}\\times agem1_{i}+ \\beta_{3}\\times black_{i}+ \\beta_{4}\\times hispan_{i} + \\beta_{5}\\times othrace_{i} + u_{i} \\] 3.4.2 操作変数の確認 なんでも操作変数に出来る訳ではありません。妥当性と外生性の2つを満たしている必要があります。 妥当性 内生変数(morekids)と相関がある. 同性の子供がいる親は追加的な子供を欲しがる傾向にある 外生性 被説明変数(weeksm1)と相関がない. 子供の性別は直接的に労働時間に影響は与えない このうち妥当性に関しては、1段階の推定でF値が10を超えるかどうかで定量的に判断出来ます。（あくまで経験則ですが…）今回の場合で実際に推定してみると、samesexはmorekidsに統計的に有意な影響をあたえており、F値も10を超えているので妥当性に関しては満たされていそうです。外生性に関しては言葉を尽くすのみです。 out_1st &lt;- lm(morekids ~ samesex + agem1 + black + hispan + othrace , data = df) summary(out_1st) ## ## Call: ## lm(formula = morekids ~ samesex + agem1 + black + hispan + othrace, ## data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.7189 -0.3869 -0.3068 0.5790 0.8164 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.1395319 0.0086985 -16.041 &lt; 2e-16 *** ## samesex 0.0680081 0.0019010 35.774 &lt; 2e-16 *** ## agem1 0.0153898 0.0002814 54.681 &lt; 2e-16 *** ## black 0.1005237 0.0043058 23.346 &lt; 2e-16 *** ## hispan 0.1512258 0.0040119 37.694 &lt; 2e-16 *** ## othrace 0.0275069 0.0045537 6.041 1.54e-09 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4796 on 254648 degrees of freedom ## Multiple R-squared: 0.02418, Adjusted R-squared: 0.02416 ## F-statistic: 1262 on 5 and 254648 DF, p-value: &lt; 2.2e-16 3.4.3 推定 操作変数の妥当性・外生性の吟味を終えたので、実際に操作変数法で推定してみましょう！AERパッケージに入っているivregという関数を使います。初めてAERパッケージを使う人は事前にinstall.packages(\"AER\")を実行してください。 library(AER) ## Loading required package: lmtest ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## Loading required package: sandwich ## Loading required package: survival ivreg(被説明変数 ~ 内生変数 + その他説明変数 | 操作変数 + その他説明変数, data = データの名前)このように書きます。今回は推定結果をout_ivに格納します。 out_iv &lt;- ivreg( weeksm1 ~ morekids + agem1 + black + hispan + othrace | samesex + agem1 + black + hispan + othrace, data = df) 3.4.4 解釈 結果をみる時は、いつも通りsummary()です。2段階目の推定結果が出力されます。基本的にはOLS推定と見方は同じです。追加的に子供が1人増えると、5.8時ほど週の労働時間が減少する傾向にあるみたいです。 summary(out_iv) ## ## Call: ## ivreg(formula = weeksm1 ~ morekids + agem1 + black + hispan + ## othrace | samesex + agem1 + black + hispan + othrace, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -36.34 -17.66 -10.99 22.72 45.15 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4.79189 0.40657 -11.786 &lt;2e-16 *** ## morekids -5.82105 1.24631 -4.671 3e-06 *** ## agem1 0.83160 0.02289 36.336 &lt;2e-16 *** ## black 11.62327 0.22893 50.772 &lt;2e-16 *** ## hispan 0.40418 0.25986 1.555 0.12 ## othrace 2.13096 0.20586 10.352 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21.38 on 254648 degrees of freedom ## Multiple R-Squared: 0.04368, Adjusted R-squared: 0.04366 ## Wald test: 1335 on 5 and 254648 DF, p-value: &lt; 2.2e-16 3.5 推定結果の整理 さて、操作変数法を使ったことでOLS推定での結果からどのように変化をしたか検討してみます。OLS推定だと、働きたくない人（労働時間を短い人）ほど、子供を多く出産する逆の因果性による効果もパラメータの値に含まれてしまうので、morekidsのパラメータの値は大きく推定されると予想出来ます。 out_OLS &lt;- lm(weeksm1 ~ morekids + agem1 + black + hispan + othrace , data = df) 複数の推定結果を比較する際には、このstargazerというライブラリが便利です。 library(stargazer) ## ## Please cite as: ## Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables. ## R package version 5.2.2. https://CRAN.R-project.org/package=stargazer 推定結果を見てみると、確かに操作変数法を使ったことで、少しパラメータの値が小さくなっていることがわかります。stargazerのより詳しい説明はこちらです。 stargazer(out_OLS, out_iv, type=&quot;text&quot;) ## ## ============================================================================ ## Dependent variable: ## ------------------------------------------ ## weeksm1 ## OLS instrumental ## variable ## (1) (2) ## ---------------------------------------------------------------------------- ## morekids -6.230*** -5.821*** ## (0.088) (1.246) ## ## agem1 0.838*** 0.832*** ## (0.013) (0.023) ## ## black 11.664*** 11.623*** ## (0.192) (0.229) ## ## hispan 0.466*** 0.404 ## (0.179) (0.260) ## ## othrace 2.142*** 2.131*** ## (0.203) (0.206) ## ## Constant -4.835*** -4.792*** ## (0.385) (0.407) ## ## ---------------------------------------------------------------------------- ## Observations 254,654 254,654 ## R2 0.044 0.044 ## Adjusted R2 0.044 0.044 ## Residual Std. Error (df = 254648) 21.384 21.385 ## F Statistic 2,330.779*** (df = 5; 254648) ## ============================================================================ ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 "],["DC.html", "Chapter 4 離散選択モデル 4.1 検証する仮説 4.2 データの読み込み 4.3 データの把握 4.4 推定 4.5 推定結果の整理", " Chapter 4 離散選択モデル 4.1 検証する仮説 「自社の店舗が多い地域ほど出店確率が高まるのでは？」という仮説をFamilymartに関して検証してみます。ドミナント戦略が取られていれば、この仮説通りになっているはずです。三田論コンビニ班の簡易的な分析です。 4.2 データの読み込み 各（メッシュ）地域における、2011年~2018年ごとのFamilymart, LAWSONの参入行動とその地域特性を示したデータです。例えば、メッシュ地域362327851（head()でデータを見た時に一番上にでてくる地域）は2013年にFamilymartが初めて参入したことがわかります。 df &lt;- read.csv(&#39;data/Mitaron_convenience.csv&#39;) head(df) ## Mesh_area Open_year Familymart_Entry LAWSON_Entry ## 1 362327851 2011 0 0 ## 2 362327851 2012 0 0 ## 3 362327851 2013 1 0 ## 4 362327851 2014 0 0 ## 5 362327851 2015 0 0 ## 6 362327851 2016 0 0 ## Familymart_existed LAWSON_existed pop n_employee ## 1 0 0 13 2 ## 2 0 0 13 2 ## 3 0 0 13 2 ## 4 1 0 13 2 ## 5 1 0 10 2 ## 6 1 0 10 2 ## super_count F_count L_count ## 1 1 1 0 ## 2 1 1 0 ## 3 1 1 0 ## 4 1 1 0 ## 5 1 1 0 ## 6 1 1 0 ○変数の説明 変数名 説明 Mesh_area メッシュ地域 Open_year 2011~2018年 Familymart_Entry Familymartの参入したら1をとるダミー変数 LAWSON_Entry LAWSONの参入したら1をとるダミー変数 Familymart_existed Familymartの既存店舗数 LAWSON_existed LAWSONの既存店舗数 pop 当該地域の従業員の人口 n_employee 当該地域の従業員の数 super_count スーパーの店舗数 4.3 データの把握 summary(df) ## Mesh_area Open_year Familymart_Entry ## Min. :362327851 Min. :2011 Min. :0.00000 ## 1st Qu.:392725222 1st Qu.:2013 1st Qu.:0.00000 ## Median :392726806 Median :2014 Median :0.00000 ## Mean :389777896 Mean :2014 Mean :0.08962 ## 3rd Qu.:392746145 3rd Qu.:2016 3rd Qu.:0.00000 ## Max. :402707402 Max. :2018 Max. :1.00000 ## LAWSON_Entry Familymart_existed LAWSON_existed ## Min. :0.00000 Min. :0.0000 Min. :0.0000 ## 1st Qu.:0.00000 1st Qu.:0.0000 1st Qu.:0.0000 ## Median :0.00000 Median :0.0000 Median :0.0000 ## Mean :0.05601 Mean :0.4611 Mean :0.3626 ## 3rd Qu.:0.00000 3rd Qu.:1.0000 3rd Qu.:1.0000 ## Max. :1.00000 Max. :5.0000 Max. :5.0000 ## pop n_employee super_count ## Min. : 1.0 Min. : 2.0 Min. :0.0000 ## 1st Qu.: 539.8 1st Qu.: 102.0 1st Qu.:0.0000 ## Median :1224.5 Median : 279.0 Median :0.0000 ## Mean :1484.6 Mean : 611.7 Mean :0.5377 ## 3rd Qu.:2140.5 3rd Qu.: 705.0 3rd Qu.:1.0000 ## Max. :5244.0 Max. :12554.0 Max. :8.0000 ## F_count L_count ## Min. :0.0000 Min. :0.0000 ## 1st Qu.:0.0000 1st Qu.:0.0000 ## Median :1.0000 Median :0.0000 ## Mean :0.7264 Mean :0.4764 ## 3rd Qu.:1.0000 3rd Qu.:1.0000 ## Max. :3.0000 Max. :2.0000 4.4 推定 4.4.1 計量経済学モデル 今回は被説明変数Familymart\\_Entry_iがダミー変数を取る（0と1だけなので離散変数）ので、ロジットモデルやプロビットモデルに代表される離散選択モデルで推定します。\\(\\lambda_i\\)が\\(\\mu\\)より大きい場合にFamilymart\\_Entry_iが1を取り、それ以外の場合にFamilymart\\_Entry_iが0を取るというモデルを考えます。 \\[ Familymart\\_Entry_{i} = \\begin{cases} 1 &amp; (\\lambda_i \\ge \\mu) \\\\ 0 &amp; (\\lambda_i &lt; \\mu) \\end{cases} \\] \\(\\lambda_i\\)は以下のような回帰式で表現出来るとします。今回の仮説が成り立っているなら、\\(\\beta_{1}\\)は正になるはずです。 \\[ \\lambda_{i} = \\alpha + \\beta_{1}\\times Familymart\\_existed_{i}+ \\beta_{2}\\times pop_{i} + u_{i} \\] 離散選択モデルでは、選択確率を求めることが出来ます。\\(P(Familymart\\_Entry = 1)\\)はFamilymartが参入する確率です。\\(F(\\cdot)\\)は累積分布関数を示しており、ロジットモデルなら、ロジスティック分布、プロビットモデルなら標準正規分布の累積分布関数である。 \\[ P(Familymart\\_Entry = 1) = F(\\alpha + \\beta_{1}\\times Familymart\\_existed_{i}+ \\beta_{2}\\times pop_{i} + u_{i} ) \\] ロジットモデルとプロビットモデルの両方でこれから推定してみます。 4.4.2 ロジットモデル ロジットモデルを推定する際はglm()関数を使います。基本的にはOLS推定と一緒ですが、()内でロジットモデルであることを指定するため、family = binominal(link = \"logit\")と指定します。結果をout_logitに保存します。 out_logit &lt;- glm( Familymart_Entry ~ Familymart_existed + pop, family = binomial(link = &quot;logit&quot;), data = df) 4.4.3 解釈 推定結果を出力する時にはいつも通りsummary()です。 summary(out_logit) ## ## Call: ## glm(formula = Familymart_Entry ~ Familymart_existed + pop, family = binomial(link = &quot;logit&quot;), ## data = df) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.7445 -0.4593 -0.4129 -0.3569 3.0002 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.502e+00 1.439e-01 -17.385 &lt; 2e-16 ## Familymart_existed -5.813e-01 1.589e-01 -3.659 0.000253 ## pop 2.595e-04 7.334e-05 3.538 0.000404 ## ## (Intercept) *** ## Familymart_existed *** ## pop *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1023.2 on 1695 degrees of freedom ## Residual deviance: 1002.4 on 1693 degrees of freedom ## AIC: 1008.4 ## ## Number of Fisher Scoring iterations: 5 離散選択モデルのポイントとして、結果を解釈する際にパラメータの値をそのまま使うことが出来ません。その代わりに、いくつか係数を解釈する際に使われる項目がありますが、ここでは平均限界効果を紹介します。この指標は、ある説明変数を1単位増やした際に、確率が平均的にどの程度変化するのかを表すものです。ライブラリmarginsを使えば、一瞬で出力されます。 library(margins) 既存店舗が1店舗増えることで、参入確率は4.6%ほど下がる傾向にあるみたいです。仮説は検証されませんでしたね。 summary(margins(out_logit)) ## factor AME SE z p lower ## Familymart_existed -0.0468 0.0130 -3.6026 0.0003 -0.0723 ## pop 0.0000 0.0000 3.4951 0.0005 0.0000 ## upper ## -0.0214 ## 0.0000 4.4.4 プロビットモデル プロビットモデルもロジットモデルとほぼ同じです。唯一違うのはfamily = binominal(link = \"probit\")と指定して、プロビットモデルで推定することを明示します。 out_probit &lt;- glm( Familymart_Entry ~ Familymart_existed + pop, family = binomial(link = &quot;probit&quot;), data = df) 4.4.5 解釈 こちらも同じです。 summary(out_probit) ## ## Call: ## glm(formula = Familymart_Entry ~ Familymart_existed + pop, family = binomial(link = &quot;probit&quot;), ## data = df) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.7137 -0.4597 -0.4145 -0.3627 3.0476 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.438e+00 7.199e-02 -19.976 &lt; 2e-16 ## Familymart_existed -2.681e-01 7.584e-02 -3.535 0.000408 ## pop 1.300e-04 3.818e-05 3.406 0.000659 ## ## (Intercept) *** ## Familymart_existed *** ## pop *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1023.2 on 1695 degrees of freedom ## Residual deviance: 1003.3 on 1693 degrees of freedom ## AIC: 1009.3 ## ## Number of Fisher Scoring iterations: 5 こちらも同じです。少し確率は下がったようです。 summary(margins(out_probit)) ## factor AME SE z p lower ## Familymart_existed -0.0426 0.0121 -3.5112 0.0004 -0.0664 ## pop 0.0000 0.0000 3.3889 0.0007 0.0000 ## upper ## -0.0188 ## 0.0000 4.5 推定結果の整理 ロジットモデルとプロビットモデルの結果を比較してみます library(stargazer) ちなみに、OLS推定でも推定自体は出来ます。線形確率モデルとも呼ばれたりします。 out_OLS &lt;- lm(Familymart_Entry ~ Familymart_existed + pop, data = df) ロジットモデルとプロビットモデルとで正負は一致しています。 stargazer(out_OLS, out_logit, out_probit, type=&quot;text&quot;) ## ## =============================================================== ## Dependent variable: ## ------------------------------------------- ## Familymart_Entry ## OLS logistic probit ## (1) (2) (3) ## --------------------------------------------------------------- ## Familymart_existed -0.039*** -0.581*** -0.268*** ## (0.010) (0.159) (0.076) ## ## pop 0.00002*** 0.0003*** 0.0001*** ## (0.00001) (0.0001) (0.00004) ## ## Constant 0.076*** -2.502*** -1.438*** ## (0.011) (0.144) (0.072) ## ## --------------------------------------------------------------- ## Observations 1,696 1,696 1,696 ## R2 0.011 ## Adjusted R2 0.010 ## Log Likelihood -501.215 -501.668 ## Akaike Inf. Crit. 1,008.430 1,009.337 ## Residual Std. Error 0.284 (df = 1693) ## F Statistic 9.840*** (df = 2; 1693) ## =============================================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 "],["PANEL.html", "Chapter 5 パネルデータ分析 5.1 検証する仮説 5.2 データの読み込み 5.3 データの把握 5.4 推定 5.5 推定結果の整理", " Chapter 5 パネルデータ分析 5.1 検証する仮説 「当該路線上で市場集中度が高いほど、運賃は高くなるのでは？」という仮説を検証してみます。市場集中度を示す値として、今回の分析では各路線上でトップシェアを誇るエアラインの市場シェアを使って分析していきます。 5.2 データの読み込み library(openxlsx) df &lt;- read.xlsx(&quot;data/airfare.xlsx&quot;) head(df) ## year origin destin dist passen fare bmktshr ## 1 1997 &quot;AKRON, OH&quot; &quot;ATLANTA, GA&quot; 528 152 106 0.8386 ## 2 1998 &quot;AKRON, OH&quot; &quot;ATLANTA, GA&quot; 528 265 106 0.8133 ## 3 1999 &quot;AKRON, OH&quot; &quot;ATLANTA, GA&quot; 528 336 113 0.8262 ## 4 2000 &quot;AKRON, OH&quot; &quot;ATLANTA, GA&quot; 528 298 123 0.8612 ## 5 1997 &quot;AKRON, OH&quot; &quot;ORLANDO, FL&quot; 861 282 104 0.5798 ## 6 1998 &quot;AKRON, OH&quot; &quot;ORLANDO, FL&quot; 861 178 105 0.5817 ## ID ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 2 ## 6 2 5.3 データの把握 5.3.1 基本統計量 summary(df) ## year origin destin ## Min. :1997 Length:4596 Length:4596 ## 1st Qu.:1998 Class :character Class :character ## Median :1998 Mode :character Mode :character ## Mean :1998 ## 3rd Qu.:1999 ## Max. :2000 ## dist passen fare ## Min. : 95.0 Min. : 2.0 Min. : 37.0 ## 1st Qu.: 505.0 1st Qu.: 215.0 1st Qu.:123.0 ## Median : 861.0 Median : 357.0 Median :168.0 ## Mean : 989.7 Mean : 636.8 Mean :178.8 ## 3rd Qu.:1304.0 3rd Qu.: 717.0 3rd Qu.:225.0 ## Max. :2724.0 Max. :8497.0 Max. :522.0 ## bmktshr ID ## Min. :0.1605 Min. : 1 ## 1st Qu.:0.4650 1st Qu.: 288 ## Median :0.6039 Median : 575 ## Mean :0.6101 Mean : 575 ## 3rd Qu.:0.7531 3rd Qu.: 862 ## Max. :1.0000 Max. :1149 5.3.2 データの可視化 library(ggpubr) ## Loading required package: ggplot2 ## ## Attaching package: &#39;ggplot2&#39; ## The following objects are masked from &#39;package:psych&#39;: ## ## %+%, alpha gghistogram(df, x = &quot;fare&quot;, bins = 30, title = &quot;Histogram of fare&quot;) 5.3.3 対数変換 df$ln_fare &lt;- log(df$fare) gghistogram(df, x = &quot;ln_fare&quot;, bins = 30, title = &quot;Histogram of ln_fare&quot;) 5.4 推定 5.4.1 計量経済学モデル \\[ ln\\_fare_{i,t} = \\alpha + \\beta_{1}\\times bmktshr_{i,t}+ \\beta_{2}\\times dist_{i,t}+ \\beta_{3}\\times passen_{i,t}+ F_i + u_{i,t} \\] 5.4.2 準備 library(plm) df_panel &lt;- pdata.frame(df, index = c(&#39;ID&#39;, &#39;year&#39;)) 5.4.3 変量効果モデル out_random &lt;- plm(ln_fare ~ bmktshr+ dist + passen , data = df_panel, model = &quot;random&quot;) summary(out_random) ## Oneway (individual) effect Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = ln_fare ~ bmktshr + dist + passen, data = df_panel, ## model = &quot;random&quot;) ## ## Balanced Panel: n = 1149, T = 4, N = 4596 ## ## Effects: ## var std.dev share ## idiosyncratic 0.01182 0.10871 0.103 ## individual 0.10290 0.32078 0.897 ## theta: 0.8329 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. ## -0.87882871 -0.06663365 -0.00065108 0.06643019 ## Max. ## 0.89768536 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 4.7083e+00 2.9902e-02 157.4573 &lt; 2.2e-16 *** ## bmktshr 9.0534e-02 2.7385e-02 3.3059 0.0009466 *** ## dist 4.3095e-04 1.6696e-05 25.8108 &lt; 2.2e-16 *** ## passen -1.4828e-04 9.6610e-06 -15.3481 &lt; 2.2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 68.334 ## Residual Sum of Squares: 56.06 ## R-Squared: 0.17962 ## Adj. R-Squared: 0.17908 ## Chisq: 1005.39 on 3 DF, p-value: &lt; 2.22e-16 5.4.4 固定効果モデル out_fix &lt;- plm(ln_fare ~ bmktshr+ dist + passen , data = df_panel, model = &quot;within&quot;) summary(out_fix) ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = ln_fare ~ bmktshr + dist + passen, data = df_panel, ## model = &quot;within&quot;) ## ## Balanced Panel: n = 1149, T = 4, N = 4596 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. ## -0.88515181 -0.04866045 -0.00023397 0.05151268 ## Max. ## 0.95497340 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## bmktshr 0.02373293 0.03000237 0.791 0.429 ## passen -0.00029409 0.00001540 -19.097 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 45.169 ## Residual Sum of Squares: 40.716 ## R-Squared: 0.098576 ## Adj. R-Squared: -0.20234 ## F-statistic: 188.365 on 2 and 3445 DF, p-value: &lt; 2.22e-16 固定効果自体はfixefで取り出せます。 mean(fixef(out_fix)) ## [1] 5.268405 5.4.5 ハウスマン検定 phtest(out_fix, out_random) ## ## Hausman Test ## ## data: ln_fare ~ bmktshr + dist + passen ## chisq = 157.91, df = 2, p-value &lt; 2.2e-16 ## alternative hypothesis: one model is inconsistent 5.4.6 固定効果×時間効果 \\[ ln\\_fare_{i,t} = \\alpha + \\beta_{1}\\times bmktshr_{i,t}+ \\beta_{2}\\times dist_{i,t}+ \\beta_{3}\\times passen_{i,t}+ F_i +y\\_1997_{i, t} +y\\_1998_{i, t} +y\\_1999_{i, t} + u_{i,t} \\] out_fix_time &lt;- plm(ln_fare ~ bmktshr+ dist + passen , data = df_panel, effect = &quot;twoways&quot;, model = &quot;within&quot;) summary(out_fix_time) ## Twoways effects Within Model ## ## Call: ## plm(formula = ln_fare ~ bmktshr + dist + passen, data = df_panel, ## effect = &quot;twoways&quot;, model = &quot;within&quot;) ## ## Balanced Panel: n = 1149, T = 4, N = 4596 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -0.819590 -0.035576 0.001385 0.037447 0.872410 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## bmktshr 8.3408e-02 2.6626e-02 3.1326 0.001747 ** ## passen -4.0067e-04 1.4055e-05 -28.5066 &lt; 2.2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 39.434 ## Residual Sum of Squares: 31.6 ## R-Squared: 0.19867 ## Adj. R-Squared: -0.069759 ## F-statistic: 426.68 on 2 and 3442 DF, p-value: &lt; 2.22e-16 5.5 推定結果の整理 library(stargazer) out_OLS &lt;- lm(ln_fare ~ bmktshr+ dist + passen , data = df) stargazer(out_OLS, out_fix, out_random, out_fix_time, type=&quot;text&quot;) ## ## ================================================================================================================ ## Dependent variable: ## -------------------------------------------------------------------------------------------- ## ln_fare ## OLS panel ## linear ## (1) (2) (3) (4) ## ---------------------------------------------------------------------------------------------------------------- ## bmktshr 0.261*** 0.024 0.091*** 0.083*** ## (0.030) (0.030) (0.027) (0.027) ## ## dist 0.0005*** 0.0004*** ## (0.00001) (0.00002) ## ## passen -0.0001*** -0.0003*** -0.0001*** -0.0004*** ## (0.00001) (0.00002) (0.00001) (0.00001) ## ## Constant 4.508*** 4.708*** ## (0.027) (0.030) ## ## ---------------------------------------------------------------------------------------------------------------- ## Observations 4,596 4,596 4,596 4,596 ## R2 0.396 0.099 0.180 0.199 ## Adjusted R2 0.395 -0.202 0.179 -0.070 ## Residual Std. Error 0.339 (df = 4592) ## F Statistic 1,002.387*** (df = 3; 4592) 188.365*** (df = 2; 3445) 1,005.385*** 426.680*** (df = 2; 3442) ## ================================================================================================================ ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 "],["Others.html", "Chapter 6 参考リンク 6.1 Web スクレイピング 6.2 地理情報講座 6.3 パネルデータ分析 6.4 dplyr入門 6.5 ggplot2 入門 6.6 stringr入門 6.7 lubridate 6.8 その他有用なサイト", " Chapter 6 参考リンク 6.1 Web スクレイピング RでのWeb スクレイピング入門 - Rを使ってWeb上のデータを収集する方法を解説した記事です。 - 後述の地理情報講座とリンクしています。 6.2 地理情報講座 【地理情報講座#1】Rでのジオコーディング入門 - ジオコーディング（住所を緯度経度に変換する）に関して解説した記事です。 【地理情報講座#2】Rでのメッシュ統計データ入門 - メッシュ統計データの使い方を解説した記事です。 【地理情報講座#3】Rでの距離計算入門 - 市場競争度の代替指標として使われる店舗間の距離をどう計算するかについて解説した記事です。 6.3 パネルデータ分析 Rでのパネルデータ加工 - 実証分析でよく使われるパネルデータの作り方が学べる記事です。 6.4 dplyr入門 dplyrは実証分析の一番重要かつ時間のかかるパートであるデータ加工を簡単に直感的に行えるライブラリです。 - dplyr入門 (新版) - dplyrを使いこなす！基礎編 - データ操作 -kazutan on web 6.5 ggplot2 入門 ggplot2はデータの可視化を簡単に直感的に行えるライブラリです。 - ggplot2による可視化入門 - ggplot2入門 [基礎編] 6.6 stringr入門 stringrは文字列の処理を簡単に直感的に行えるライブラリです。 - stringrを使って文字列処理をやってみる 6.7 lubridate lubridateは日付・時刻の処理を簡単に直感的に行えるライブラリです。 - 日付・時刻処理の決定版！lubridateの使い方 - ログデータ処理で学ぶlubridate入門 6.8 その他有用なサイト R Econ Visual Library - 世銀が公開しているデータ可視化のTips集です。 Tidyverse design guide - tidyverseライブラリ(dplyr, ggplot2などなど)の使い方に関するTips集です。 R for Data Science - Rでデータサイエンスを体系的に学べる教材です。tidyverseも同時に学べます。 R for Data Science: Answers - 上の本の答えです。 "]]
